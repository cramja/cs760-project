---
layout: page
title:  "Introduction"
date:   2017-05-04 08:35:48 -0500
categories: project
---

# Understanding Variance Reduction Techniques with SGD

Stochastic Gradient Descent (SGD) is the workhorse behind many machine learning tasks. It's used to train many common classifiers like linear classifiers and SVMs, as well as large non-convex problems like neural networks. In general, SGD has a small memory footprint, learns quickly, and is robust to noise- all good things to have in a training algorithm. However, SGD has high variance between applications of the gradient function which can be inefficient. The research community has addressed this problem by introducing Variance Reduction (VR) techniques.

In this article, we wish to give an intuitive understanding of how variance reduction (VR) techniques work when applied to SGD. To this end, we have constructed an interactive visualization of an SVM learning in real time, using one of 3 possible update algorithms. We also implemented several algorithms in C++ and tested them on real world datasets to learn how the algorithm's differ in time to convergence.

## SGD Background

In its simplest form, we can write the stochastic update function as

$$w_{i+1} = w_{i} - \eta(\nabla f_i(x_j))$$

where $$x_j$$ is single randomly selected training example, and $$w_i$$ is the weight vector at time $$i$$. $$\nabla f$$ is the gradient of our loss function, $$f$$. Each iteration $$i$$ changes the weight vector by taking a step of size $$\eta$$ in the opposite direction of greatest positive change (i.e. we are reducing the loss). After some number of iterations, or when $$w_{i} - w_{i+1}$$ is sufficiently small, we consider ourselves converged.

SGD is often compared to the Gradient Descent which, instead of calculating $$\nabla f_i(x_j)$$, calculates $$\nabla f_i(X)$$ where $$X$$ is the entire training set. $$\nabla f_i(X)$$ is sometimes called the *true gradient* because it is the actual gradient at $$i$$ whereas $$\nabla f_i(x_j)$$ is merely an approximation of the true gradient at $$i$$. Because gradients in GD are accurate, we can use a larger learning rate than SGD. However, SGD generally converges faster than GD. If $$n$$ is the number of training examples, we generally use let $$\eta _{SGD} > \frac{\eta _{GD}}{n}$$ meaning that if SGD's gradients are mostly accurate, we should converge faster than GD because we apply many more gradient per unit time.

One of the main weaknesses of SGD is the imprecision of the stochastic gradients. The problem is that gradients tend to bounce around in varying directions, so instead of smoothly approaching our converged error, we will tend to jitter. 

<a href="/assets/SGDvGD.svg"><img src="/assets/SGDvGD.svg"></a>

The image shows a sketch of the error rate as we train. In the ideal case, error should be strictly decreasing, however, this is often not the case for SGD.

## VR Algorithms Overview

**[TODO]** Give an intuition for what VR is doing (Variance, expected values, etc).

### ASGD